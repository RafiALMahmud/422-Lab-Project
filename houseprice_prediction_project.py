# -*- coding: utf-8 -*-
"""houseprice prediction project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hcS1XSJAkJRI3_KaoOQn8-ZaXGkTrybX
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from google.colab import drive

from google.colab import drive
drive.mount('/content/drive')

dataset = pd.read_csv('/content/drive/MyDrive/project460_dataset/housing_price_dataset.csv')
dataset.head(10)

dataset.info()

dataset.shape

"""# Handling Missing Values & Duplicate Values




"""

dataset.isnull().sum()

print("Shape of dataframe before dropping:", dataset.shape)
dataset = dataset.dropna(axis = 0, subset = ['SquareFeet'])
dataset = dataset.dropna(axis = 0, subset = ['Bedrooms'])
dataset = dataset.dropna(axis = 0, subset = ['Bathrooms'])
dataset = dataset.dropna(axis = 0, subset = ['Neighborhood'])
dataset = dataset.dropna(axis = 0, subset = ['YearBuilt'])
dataset = dataset.dropna(axis = 0, subset = ['Price'])
print("Shape after dropping:", dataset.shape)

dataset.isnull().sum()

dataset.duplicated().sum()

"""# Handling Categorical features"""

dataset['Neighborhood'].unique()

Neighborhood_enc = pd.get_dummies(dataset['Neighborhood'])

Neighborhood_enc = Neighborhood_enc.astype(int)

dataset = pd.concat([dataset, Neighborhood_enc], axis=1)
dataset = dataset.drop('Neighborhood', axis=1)

dataset.head(10)

dataset = dataset.drop(' ', axis=1)

dataset.info()

dataset['Bathrooms'] = dataset['Bathrooms'].str.replace(',', '').str.replace('$', '').str.replace(' ', '')
dataset['Bathrooms'] = pd.to_numeric(dataset['Bathrooms'], errors='coerce')

dataset.info()

dataset['Price'] = dataset['Price'].str.replace(',', '').str.replace('$', '').str.replace(' ', '')
dataset['Price'] = pd.to_numeric(dataset['Price'], errors='coerce')

dataset.info()

dataset.head(10)

dataset.isnull().sum()

dataset = dataset.dropna(axis = 0, subset = ['Bathrooms'])
dataset = dataset.dropna(axis = 0, subset = ['Price'])

dataset.isnull().sum()

"""# Correlation"""

dataset_corr = dataset.corr()
dataset_corr

import seaborn as sns

sns.heatmap(dataset_corr, cmap = 'YlGnBu')



"""# Splitting the independent and dependent variables"""

X = dataset[['SquareFeet', 'Bedrooms', 'Bathrooms', 'YearBuilt', 'Rural', 'Suburb', 'Urban']]  # Independent variables
Y = dataset['Price']  # Dependent variable (Price)

X

Y

"""# **Splitting in Training set and testing set**"""

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)

X_train

X_test

Y_train

Y_test

"""# Scatter Matrix"""

from pandas.plotting import scatter_matrix
import pandas as pd

# Assuming your dataset is named 'dataset' and has columns like 'SquareFeet', 'Bedrooms', 'Bathrooms', 'YearBuilt', 'Rural', 'Suburb', 'Urban', and 'Price'

# Select the features for the scatter matrix
features = ['SquareFeet', 'Bedrooms', 'Bathrooms', 'YearBuilt', 'Rural', 'Suburb', 'Urban']

# Create a DataFrame with the selected features
df = pd.DataFrame(data=dataset[features], columns=features)

# Create the scatter matrix plot
scatter_matrix(df, c=dataset['Price'], figsize=(12, 12), alpha=0.5, diagonal='hist')  # 'c' specifies the color based on 'Price'
plt.show()  # Display the plot

"""# Feature Scaling"""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_train

X_test



"""# Linear Regression"""

# Import the necessary library
from sklearn.linear_model import LinearRegression
clf1 = LinearRegression()
clf1.fit(X_train, Y_train)

print("Training accuracy of the model is {:.2f}".format(clf1.score(X_train, Y_train)))
print("Testing accuracy of the model is {:.2f}".format(clf1.score(X_test, Y_test)))

#Predicting on testing set
Y_pred1 = clf1.predict(X_test)

Y_pred1

"""# Random Forest Regressor"""

#Training on training set
from sklearn.ensemble import RandomForestRegressor # Import RandomForestRegressor
clf3 = RandomForestRegressor(n_estimators = 100, random_state = 42) # Use RandomForestRegressor for continuous target variables
clf3.fit(X_train, Y_train)

print("Training accuracy of the model is {:.2f}".format(clf3.score(X_train, Y_train)))
print("Testing accuracy of the model is {:.2f}".format(clf3.score(X_test, Y_test)))

#Predicting on testing set
Y_pred3 = clf3.predict(X_test)

Y_pred3

"""# XGBoost"""

!pip install xgboost==1.7.5

import xgboost as xgb
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

clf5 = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
clf5.fit(X_train, Y_train)


Y_pred5 = clf5.predict(X_test)

print("Training accuracy of the model is {:.2f}".format(clf5.score(X_train, Y_train)))
print("Testing accuracy of the model is {:.2f}".format(clf5.score(X_test, Y_test)))

"""# Evalualtion"""

from sklearn.metrics import mean_squared_error, r2_score

def get_metrics(model_name, y_test, y_pred):
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r_squared = r2_score(y_test, y_pred)


    print(f"{model_name} Metrics:")
    print(f"MSE: {mse}")
    print(f"RMSE: {rmse}")
    print(f"R-squared: {r_squared}")

    print()

    return mse, rmse, r_squared

lr_metrics = get_metrics("Linear Regression", Y_test, Y_pred1)

rf_metrics = get_metrics("Random Forest Regressor", Y_test, Y_pred3)
xg_metrics = get_metrics("XGBoost", Y_test, Y_pred5)

"""# Comparison"""

lr_mse, lr_rmse, lr_r2 = lr_metrics

rf_mse, rf_rmse, rf_r2 = rf_metrics
xg_mse, xg_rmse, xg_r2 = xg_metrics

models = ['Linear Regression','Random Forest Regressor', "XGBoost"]
mse_values = [lr_mse, rf_mse, xg_mse]
rmse_values = [lr_rmse, rf_rmse, xg_rmse]
r2_values = [lr_r2,rf_r2, xg_r2 ]

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# MSE Plot
axes[0].bar(models, mse_values, color='red')
axes[0].set_title('Mean Squared Error (MSE)')
axes[0].set_ylabel('MSE')

# RMSE Plot
axes[1].bar(models, rmse_values, color='green')
axes[1].set_title('Root Mean Squared Error (RMSE)')
axes[1].set_ylabel('RMSE')

# R² Plot
axes[2].bar(models, r2_values, color='blue')
axes[2].set_title('R² (Coefficient of Determination)')
axes[2].set_ylabel('R²')

# Display the plots
plt.tight_layout()
plt.show()